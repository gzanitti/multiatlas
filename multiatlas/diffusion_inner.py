from __future__ import division

from collections import Counter, defaultdict
from warnings import warn

import numpy as np
import nibabel

from dipy.core.gradients import gradient_table
from dipy.reconst.csdeconv import auto_response
from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel
from dipy.direction import peaks_from_model
from dipy.data import get_sphere

from logpar.utils import cifti_utils

from .acg_distribution import lambda_estimator, density


def compute_odfs(dmri_data, bvals, bvecs, mask, sphere):
    """Returns peaks of the diffusion data on nzr_positions"""
    gtab = gradient_table(bvals, bvecs, b0_threshold=bvals.min())

    #print("PLEASE REMEMBER TO DEACTIVATE ME AFTER FINISING TESTING")
    response, _ = auto_response(gtab, dmri_data)

    csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)

    csd_peaks = peaks_from_model(model=csd_model,
                                 data=dmri_data,
                                 sphere=sphere,
                                 mask=mask,
                                 relative_peak_threshold=0.5,
                                 min_separation_angle=35,
                                 return_odf=True, return_sh=False,
                                 parallel=True, npeaks=1)
    odfs = csd_peaks.odf

    # We normalized in such a way that ||<v, v>|| = 1
    norms = (odfs*odfs).sum(-1)
    norms[norms==0] = 1
    norms = np.sqrt(norms)
    odfs = odfs / norms[:, :, :, None]

    return odfs


def streamline_directions_per_voxel(streamlines, nzrs):
    '''Given a set of streamlines, returns a dictionary with keys:voxels
       and values: normalized directions of the streamlines in that voxel'''
    dir_per_vox = defaultdict(list)

    for streamline in streamlines:
        directions = np.diff(streamline, axis=0).astype(float)

        norms = np.linalg.norm(directions, axis=1)
        directions[norms>0] /= norms[norms>0, None]

        voxels = map(tuple, np.round(streamline).astype(int))

        list(dir_per_vox[v].append(d) for d, v in zip(directions, voxels))

    dir_per_vox = {k:v for k, v in dir_per_vox.items() if k in nzrs}

    return dir_per_vox


def is_invertible(a):
    return a.shape[0] == a.shape[1] and np.linalg.matrix_rank(a) == a.shape[0]


def diffusion_weights_tract(odfs, total_subjects, tract_dict,
                            label, nzrs, sphere):
    """Returns the probability of finding the peak peaks[vox] in
       the ACGD generated by the tracts in the tract_dict for the
       label label over the nozrs voxels

       tract_dict is of the form:
        (subject, label): tracts
       nzrs is a list of voxels
       """
    if not isinstance(nzrs, list) or not isinstance(nzrs[0], tuple):
        raise ValueError('nzrs must be a list of tuples')

    weights_per_voxel = np.zeros((total_subjects, len(nzrs)))

    vox2idx = {v:i for i, v in enumerate(nzrs)}

    for subject in range(total_subjects):
        #print("Diff for subject {}".format(subject))

        if (subject, label) not in tract_dict:
            continue

        streamlines = tract_dict[(subject, label)]

        # Compute directions inside of a voxel
        dir_per_vox = streamline_directions_per_voxel(streamlines, nzrs)

        if len(dir_per_vox) == 0:
            continue

        # Estimate a lambda per voxel
        lambda_per_voxel = {v: lambda_estimator(np.array(d), iters=100)
                            for v, d in dir_per_vox.items()}

        # Estimate an odf per voxel
        odf_per_vox = {v: density(sphere.vertices, L)
                       for v, L in lambda_per_voxel.items()
                       if is_invertible(L)}

        # Retrieve the odf of the test subject
        voxels = odf_per_vox.keys()
        test_odfs = odfs[tuple(np.transpose(list(voxels)))]

        train_odfs = np.array(list(odf_per_vox.values()))

        norms = (train_odfs*train_odfs).sum(-1)
        norms[norms==0] = 1
        norms = np.sqrt(norms)
        train_odfs = train_odfs / norms[:, None]

        similarity = (test_odfs*train_odfs).sum(1)

        ids = [vox2idx[v] for v in voxels]
        weights_per_voxel[subject, ids] = similarity

    return weights_per_voxel


def multi_label_segmentation(atlases, train_tracts, test_dwi,
                             bvecs, bvals, dwi_affine, sphere='repulsion100'):
    '''Label fusion that takes into account diffusion information

       Parameters
       ----------
       atlases: array-like
           Array of shape (s,v), where s: number of subjects, v: voxels
           in the T1. Each value represents a white matter tract.
       train_tracts: dict-like
           The keys of the dictionary are tuples (s, l), where s is the
           subject number, and l is a label (corresponding to a white matter
           tract)
           The values are the streamlines of that subject, for that label
        test_dwi: array-like
           Diffusion weighted image of the subject we want to label
       #TODO
       '''
    # Compute the number of subjects
    max_subject_key = max([s for s, _ in train_tracts.keys()]) + 1
    nsubjects = max(len(atlases), max_subject_key)

    # Take the labels
    tract_labels = np.unique([v for _, v in train_tracts.keys()])
    #volume_labels = np.unique(atlases)
    #volume_labels = volume_labels[volume_labels > 0]
    volume_labels = []

    # We want to assign the label with the highest sum of weighted votes,
    # lets compute a mask of the voxels which we are going to take into
    # account in the voting to be sure to work only on those, optimizing
    # both the use of time and memory

    # Let's only use the voxels in the Grey-matter where at least 20% of the
    # subjects have a vote
    #print("Compute mask")
    #volume_mask = (atlases > 0).any(0)

    # And lets use only the voxels in the white-matter where there are more
    # than 10 streamlines passing throught
    tract_mask = np.zeros(test_dwi.shape[:3], dtype=bool)

    for tracts in train_tracts.values():
        for tract in tracts:
            tup_pos = tuple(np.round(np.transpose(tract)).astype(int))
            tract_mask[tup_pos] = True

    mask = tract_mask

    # Filter atlases, retain only the voxels in the mask
    #atlases = atlases[:, mask]

    nzrs = mask.nonzero()
    nzrs_tuple = [tuple(n) for n in np.transpose(nzrs)]

    #print("Compute peaks of test_dwi")
    sphere = get_sphere(sphere)
    test_odfs = compute_odfs(test_dwi, bvals, bvecs, mask, sphere)

    # They all start voting for backgrounds at every voxel
    background = np.ones((nsubjects, len(nzrs[0])), dtype=np.int8)

    # Max weight so far at each voxel and output segmentation
    max_weights = np.zeros(len(nzrs[0]))
    output_segmentation = np.zeros_like(max_weights)

    def update_background_and_weight_variables(weights, l):
        background[weights.nonzero()] = 0
        weights = weights.sum(0)

        bigger = weights > max_weights
        equal = weights == max_weights

        output_segmentation[bigger] = l
        output_segmentation[equal] = -1
        max_weights[bigger] = weights[bigger]

    # Compute the weight for each tract
    for l in tract_labels:
        print("Computing weights for label {}".format(l))
        weights = diffusion_weights_tract(test_odfs, nsubjects, train_tracts,
                                          l, nzrs_tuple, sphere)
        update_background_and_weight_variables(weights, l)

    # Compute the weight for each grey-matter label assuming isotropic diff
    # The value in a uniform is 1/#v, if we want <u,u> = 1, then we
    # need to normalize by 1/sqrt(#v) -> (1/#v) / (1/sqrt(#v)) = sqrt(#v)/#v
    v = len(sphere.vertices)
    uniform_density = np.sqrt(v)/v

    test_odfs = test_odfs[mask]

    odfs_uniform_inner_product = (test_odfs*uniform_density).sum(1)

    for l in volume_labels:
        #print("Computing weights for label {}".format(l))
        weights = (atlases == l) * odfs_uniform_inner_product
        update_background_and_weight_variables(weights, l)

    # Compute the background weights, assuming isotropic diffusion
    background_weights = background*odfs_uniform_inner_product

    update_background_and_weight_variables(background_weights, 0)

    output = np.zeros_like(mask, dtype=int)
    output[nzrs] = output_segmentation

    return output
